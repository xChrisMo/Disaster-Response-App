{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import sys\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, fbeta_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the specific UserWarning(tokenizer in NLP vectorizer)\n",
    "#warnings.filterwarnings(\"ignore\", message=\"The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\")\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[('Message',)]\n",
      "[('process_data_table',), ('final',), ('chrismo',)]\n"
     ]
    }
   ],
   "source": [
    "# Connect to known databases\n",
    "conn_chrismoetable = sqlite3.connect('chrismoetable.db')\n",
    "conn_disasterresponse = sqlite3.connect('DisasterResponse.db')\n",
    "conn_insertdb = sqlite3.connect('InsertDatabaseName.db')\n",
    "\n",
    "def list_tables(connection):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return connection.execute(query).fetchall()\n",
    "\n",
    "# List tables for each database\n",
    "chrismoetable_tables = list_tables(conn_chrismoetable)\n",
    "disasterresponse_tables = list_tables(conn_disasterresponse)\n",
    "insertdatabase_tables = list_tables(conn_insertdb)\n",
    "\n",
    "# Close the connections\n",
    "conn_chrismoetable.close()\n",
    "conn_disasterresponse.close()\n",
    "conn_insertdb.close()\n",
    "\n",
    "# Output the results\n",
    "print(chrismoetable_tables)\n",
    "print(disasterresponse_tables)\n",
    "print(insertdatabase_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('chrismo', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message   genre  related  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...  direct      1.0   \n",
       "1   7            Is the Hurricane over or is it not over  direct      1.0   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0      0.0    0.0          0.0           0.0               0.0   \n",
       "1      0.0    0.0          1.0           0.0               0.0   \n",
       "\n",
       "   search_and_rescue  ...  aid_centers  other_infrastructure  weather_related  \\\n",
       "0                0.0  ...          0.0                   0.0              0.0   \n",
       "1                0.0  ...          0.0                   0.0              1.0   \n",
       "\n",
       "   floods  storm  fire  earthquake  cold  other_weather  direct_report  \n",
       "0     0.0    0.0   0.0         0.0   0.0            0.0            0.0  \n",
       "1     0.0    1.0   0.0         0.0   0.0            0.0            0.0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reviewing data's completeness\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        26180\n",
       "message                   26177\n",
       "genre                         3\n",
       "related                       3\n",
       "request                       2\n",
       "offer                         2\n",
       "aid_related                   2\n",
       "medical_help                  2\n",
       "medical_products              2\n",
       "search_and_rescue             2\n",
       "security                      2\n",
       "military                      2\n",
       "water                         2\n",
       "food                          2\n",
       "shelter                       2\n",
       "clothing                      2\n",
       "money                         2\n",
       "missing_people                2\n",
       "refugees                      2\n",
       "death                         2\n",
       "other_aid                     2\n",
       "infrastructure_related        2\n",
       "transport                     2\n",
       "buildings                     2\n",
       "electricity                   2\n",
       "tools                         2\n",
       "hospitals                     2\n",
       "shops                         2\n",
       "aid_centers                   2\n",
       "other_infrastructure          2\n",
       "weather_related               2\n",
       "floods                        2\n",
       "storm                         2\n",
       "fire                          2\n",
       "earthquake                    2\n",
       "cold                          2\n",
       "other_weather                 2\n",
       "direct_report                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data\n",
    "\n",
    "X = df['message']\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4    says: west side of Haiti, rest of the country ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0      0.0    0.0          0.0           0.0               0.0   \n",
       "1      0.0    0.0          1.0           0.0               0.0   \n",
       "2      0.0    0.0          0.0           0.0               0.0   \n",
       "3      1.0    0.0          1.0           0.0               1.0   \n",
       "4      0.0    0.0          0.0           0.0               0.0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  ...  aid_centers  \\\n",
       "0                0.0       0.0       0.0    0.0   0.0  ...          0.0   \n",
       "1                0.0       0.0       0.0    0.0   0.0  ...          0.0   \n",
       "2                0.0       0.0       0.0    0.0   0.0  ...          0.0   \n",
       "3                0.0       0.0       0.0    0.0   0.0  ...          0.0   \n",
       "4                0.0       0.0       0.0    0.0   0.0  ...          0.0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "1                   0.0              1.0     0.0    1.0   0.0         0.0   \n",
       "2                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "3                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "4                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0   0.0            0.0            0.0  \n",
       "1   0.0            0.0            0.0  \n",
       "2   0.0            0.0            0.0  \n",
       "3   0.0            0.0            0.0  \n",
       "4   0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216,)\n",
      "(26216, 34)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str)-> List[str]:\n",
    "    \"\"\"\n",
    "    Tokenize and process the input text.\n",
    "\n",
    "    This function performs tokenization, stopword removal, part o speech tagging, and lemmatization on the input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed tokens.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    STOPWORDS = stopwords.words(\"english\")\n",
    "    word_tokens = [word for word in word_tokens if word not in STOPWORDS]   #stop word removal\n",
    "    \n",
    "    tokens = []\n",
    "    for word_token in word_tokens:\n",
    "        token = lemmatizer.lemmatize(word_token.lower().strip(), pos='v')        #pos tagging\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline = Pipeline([\n",
    "                    ('features', FeatureUnion([\n",
    "                        ('text_pipeline', Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                            ('tfidf_transformer', TfidfTransformer())\n",
    "                        ])),\n",
    "                    ])),\n",
    "                    ('classifier', MultiOutputClassifier())\n",
    "                ])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a list of BASE models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier()\n",
    "naive = MultinomialNB()\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "xg = XGBClassifier(random_state=42)\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [kn, naive, random_forest, xg, dec_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict() -> List[Tuple[str, float, float]]:\n",
    "    \"\"\"\n",
    "    Feeds BASE models from our list into training pipelines, predicts using training and test data to detetc over or under-fitting\n",
    "    \n",
    "    Args: \n",
    "        None\n",
    "        \n",
    "    Returns: \n",
    "        List[Tuple[str, float, float]]: A list of tuples containing model name, test accuracy, and train accuracy.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in models:\n",
    "        pipeline = Pipeline([\n",
    "            ('features', FeatureUnion([\n",
    "                ('text_pipeline', TfidfVectorizer(tokenizer=tokenize))\n",
    "            ])),\n",
    "            ('classifier', MultiOutputClassifier(model))\n",
    "        ])\n",
    "        model_name = model.__class__.__name__\n",
    "        print(model_name)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        test_accuracy = accuracy_score(y_test, pipeline.predict(X_test))\n",
    "        print(f'Test Accuracy = {test_accuracy}')\n",
    "        train_accuracy = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "        print(f'Train Accuracy = {train_accuracy}')\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        results.append((model_name, test_accuracy, train_accuracy))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "Test Accuracy = 0.42523649679584985\n",
      "Train Accuracy = 0.4837249516834503\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "MultinomialNB\n",
      "Test Accuracy = 0.3642050656087885\n",
      "Train Accuracy = 0.3977723527616723\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier\n",
      "Test Accuracy = 0.4104363747329875\n",
      "Train Accuracy = 0.9971518665446037\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "XGBClassifier\n",
      "Test Accuracy = 0.4247787610619469\n",
      "Train Accuracy = 0.6004984233546944\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier\n",
      "Test Accuracy = 0.2551113823619164\n",
      "Train Accuracy = 0.9979656189604312\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('KNeighborsClassifier', 0.42523649679584985, 0.4837249516834503),\n",
       " ('MultinomialNB', 0.3642050656087885, 0.3977723527616723),\n",
       " ('RandomForestClassifier', 0.4104363747329875, 0.9971518665446037),\n",
       " ('XGBClassifier', 0.4247787610619469, 0.6004984233546944),\n",
       " ('DecisionTreeClassifier', 0.2551113823619164, 0.9979656189604312)]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although accuracy is not our main metric here, it is a good indicator for what models to use.\n",
    "\n",
    "From our results, all our models underfit. You can use this [reference](https://aws.amazon.com/what-is/overfitting/) to understand these concepts. \n",
    "\n",
    "To put into context about our base models, \n",
    "\n",
    "* `KNeighborsClassifier` gives a very descent result out the box, the best values even though it underfits.\n",
    "* `MultinomialNB`: This Naive algorithm performs weakest using our metric here.\n",
    "* `RandomForestClassifier`: Random Forest gives a descent result, but it overfits quite largely.\n",
    "* `XGBClassifier`: Decent accuracy, only topped by our neighbors classifier. Overfits slightly less compared to other ensemble tree methods.\n",
    "* `DecisionTreeClassifier`: Doesnt do well, as we expect really.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, we would use XGBoost due to its hyperparameter tuning capabilities being so flexible and its performance out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19662,)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19662, 34)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `soft_prob` objective function means we try to obtain the probability of that input being in that exact class. It is the same logic used [here](https://forecastegy.com/posts/xgboost-multiclass-classification-python/). Now we reintroduce our training `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                    ('features', FeatureUnion([\n",
    "                        ('text_pipeline', Pipeline([\n",
    "                            ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                            ('tfidf_transformer', TfidfTransformer())\n",
    "                        ])),\n",
    "                    ])),\n",
    "                    ('classifier', MultiOutputClassifier(XGBClassifier(\n",
    "                        max_depth=6,\n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=100,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.8,\n",
    "                        eval_metric=['mlogloss', 'merror']\n",
    "                    )))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19662,)\n",
      "(19662, 34)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                  CountVectorizer(tokenizer=&lt;function tokenize at 0x3a9828ea0&gt;)),\n",
       "                                                                 (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                               booster=None,\n",
       "                                                               callbacks=None,\n",
       "                                                               colsample_bylevel=None,\n",
       "                                                               cols...\n",
       "                                                               grow_policy=None,\n",
       "                                                               importance_type=None,\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=0.1,\n",
       "                                                               max_bin=None,\n",
       "                                                               max_cat_threshold=None,\n",
       "                                                               max_cat_to_onehot=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=6,\n",
       "                                                               max_leaves=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               multi_strategy=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None,\n",
       "                                                               random_state=None, ...)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                  CountVectorizer(tokenizer=&lt;function tokenize at 0x3a9828ea0&gt;)),\n",
       "                                                                 (&#x27;tfidf_transformer&#x27;,\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                               booster=None,\n",
       "                                                               callbacks=None,\n",
       "                                                               colsample_bylevel=None,\n",
       "                                                               cols...\n",
       "                                                               grow_policy=None,\n",
       "                                                               importance_type=None,\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=0.1,\n",
       "                                                               max_bin=None,\n",
       "                                                               max_cat_threshold=None,\n",
       "                                                               max_cat_to_onehot=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=6,\n",
       "                                                               max_leaves=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               multi_strategy=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None,\n",
       "                                                               random_state=None, ...)))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;features: FeatureUnion<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.FeatureUnion.html\">?<span>Documentation for features: FeatureUnion</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FeatureUnion(transformer_list=[(&#x27;text_pipeline&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                 CountVectorizer(tokenizer=&lt;function tokenize at 0x3a9828ea0&gt;)),\n",
       "                                                (&#x27;tfidf_transformer&#x27;,\n",
       "                                                 TfidfTransformer())]))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>text_pipeline</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x3a9828ea0&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;classifier: MultiOutputClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\">?<span>Documentation for classifier: MultiOutputClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.8, device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=[&#x27;mlogloss&#x27;,\n",
       "                                                           &#x27;merror&#x27;],\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.1, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, ...))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=[&#x27;mlogloss&#x27;, &#x27;merror&#x27;],\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=[&#x27;mlogloss&#x27;, &#x27;merror&#x27;],\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                 Pipeline(steps=[('count_vectorizer',\n",
       "                                                                  CountVectorizer(tokenizer=<function tokenize at 0x3a9828ea0>)),\n",
       "                                                                 ('tfidf_transformer',\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                ('classifier',\n",
       "                 MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                               booster=None,\n",
       "                                                               callbacks=None,\n",
       "                                                               colsample_bylevel=None,\n",
       "                                                               cols...\n",
       "                                                               grow_policy=None,\n",
       "                                                               importance_type=None,\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=0.1,\n",
       "                                                               max_bin=None,\n",
       "                                                               max_cat_threshold=None,\n",
       "                                                               max_cat_to_onehot=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=6,\n",
       "                                                               max_leaves=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               multi_strategy=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None,\n",
       "                                                               random_state=None, ...)))])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6554, 34)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6554, 34)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44003661885871226"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5210049842335469"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, pipeline.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Detailed Metrics Breakdown by Category\n",
      "\n",
      "### request\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.912 |    0.975 |      0.943 |\n",
      "| 1.0          |       0.816 |    0.542 |      0.651 |\n",
      "| weighted avg |       0.896 |    0.902 |      0.893 |\n",
      "\n",
      "### offer\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.995 |    1     |      0.997 |\n",
      "| 1.0          |       0     |    0     |      0     |\n",
      "| weighted avg |       0.99  |    0.995 |      0.992 |\n",
      "\n",
      "### aid_related\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.766 |    0.872 |      0.815 |\n",
      "| 1.0          |       0.767 |    0.612 |      0.681 |\n",
      "| weighted avg |       0.766 |    0.766 |      0.761 |\n",
      "\n",
      "### medical_help\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.937 |    0.988 |      0.962 |\n",
      "| 1.0          |       0.645 |    0.254 |      0.365 |\n",
      "| weighted avg |       0.913 |    0.928 |      0.913 |\n",
      "\n",
      "### medical_products\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.963 |    0.993 |      0.978 |\n",
      "| 1.0          |       0.719 |    0.305 |      0.429 |\n",
      "| weighted avg |       0.95  |    0.957 |      0.949 |\n",
      "\n",
      "### search_and_rescue\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.98  |    0.998 |      0.989 |\n",
      "| 1.0          |       0.714 |    0.189 |      0.299 |\n",
      "| weighted avg |       0.974 |    0.978 |      0.972 |\n",
      "\n",
      "### security\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.982 |    1     |      0.991 |\n",
      "| 1.0          |       0.25  |    0.009 |      0.017 |\n",
      "| weighted avg |       0.969 |    0.982 |      0.974 |\n",
      "\n",
      "### military\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.977 |    0.994 |      0.985 |\n",
      "| 1.0          |       0.58  |    0.255 |      0.354 |\n",
      "| weighted avg |       0.965 |    0.972 |      0.966 |\n",
      "\n",
      "### water\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.979 |    0.985 |      0.982 |\n",
      "| 1.0          |       0.755 |    0.684 |      0.718 |\n",
      "| weighted avg |       0.964 |    0.966 |      0.965 |\n",
      "\n",
      "### food\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.971 |    0.979 |      0.975 |\n",
      "| 1.0          |       0.826 |    0.776 |      0.8   |\n",
      "| weighted avg |       0.955 |    0.956 |      0.955 |\n",
      "\n",
      "### shelter\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.964 |    0.982 |      0.973 |\n",
      "| 1.0          |       0.773 |    0.627 |      0.692 |\n",
      "| weighted avg |       0.947 |    0.951 |      0.948 |\n",
      "\n",
      "### clothing\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.992 |    0.997 |      0.995 |\n",
      "| 1.0          |       0.723 |    0.48  |      0.577 |\n",
      "| weighted avg |       0.988 |    0.989 |      0.988 |\n",
      "\n",
      "### money\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.985 |    0.996 |      0.991 |\n",
      "| 1.0          |       0.623 |    0.286 |      0.392 |\n",
      "| weighted avg |       0.978 |    0.982 |      0.979 |\n",
      "\n",
      "### missing_people\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.99  |    1     |      0.995 |\n",
      "| 1.0          |       0.833 |    0.137 |      0.235 |\n",
      "| weighted avg |       0.989 |    0.99  |      0.987 |\n",
      "\n",
      "### refugees\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.975 |    0.993 |      0.984 |\n",
      "| 1.0          |       0.571 |    0.26  |      0.358 |\n",
      "| weighted avg |       0.962 |    0.969 |      0.964 |\n",
      "\n",
      "### death\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.977 |    0.994 |      0.985 |\n",
      "| 1.0          |       0.798 |    0.505 |      0.619 |\n",
      "| weighted avg |       0.969 |    0.972 |      0.969 |\n",
      "\n",
      "### other_aid\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.882 |    0.988 |      0.932 |\n",
      "| 1.0          |       0.631 |    0.131 |      0.217 |\n",
      "| weighted avg |       0.849 |    0.875 |      0.838 |\n",
      "\n",
      "### infrastructure_related\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.94  |    0.995 |      0.967 |\n",
      "| 1.0          |       0.429 |    0.051 |      0.091 |\n",
      "| weighted avg |       0.908 |    0.936 |      0.912 |\n",
      "\n",
      "### transport\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.964 |    0.996 |      0.979 |\n",
      "| 1.0          |       0.716 |    0.224 |      0.342 |\n",
      "| weighted avg |       0.952 |    0.96  |      0.95  |\n",
      "\n",
      "### buildings\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.968 |    0.995 |      0.981 |\n",
      "| 1.0          |       0.791 |    0.375 |      0.508 |\n",
      "| weighted avg |       0.96  |    0.964 |      0.958 |\n",
      "\n",
      "### electricity\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.982 |    0.997 |      0.99  |\n",
      "| 1.0          |       0.66  |    0.224 |      0.335 |\n",
      "| weighted avg |       0.975 |    0.98  |      0.975 |\n",
      "\n",
      "### tools\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.993 |    1     |      0.997 |\n",
      "| 1.0          |       0     |    0     |      0     |\n",
      "| weighted avg |       0.987 |    0.993 |      0.99  |\n",
      "\n",
      "### hospitals\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.992 |    0.998 |      0.995 |\n",
      "| 1.0          |       0.286 |    0.071 |      0.114 |\n",
      "| weighted avg |       0.986 |    0.991 |      0.988 |\n",
      "\n",
      "### shops\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.996 |    1     |      0.998 |\n",
      "| 1.0          |       0     |    0     |      0     |\n",
      "| weighted avg |       0.993 |    0.996 |      0.995 |\n",
      "\n",
      "### aid_centers\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.988 |    0.999 |      0.993 |\n",
      "| 1.0          |       0.125 |    0.012 |      0.022 |\n",
      "| weighted avg |       0.977 |    0.987 |      0.981 |\n",
      "\n",
      "### other_infrastructure\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.958 |    0.998 |      0.978 |\n",
      "| 1.0          |       0.421 |    0.028 |      0.053 |\n",
      "| weighted avg |       0.935 |    0.956 |      0.938 |\n",
      "\n",
      "### weather_related\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.882 |    0.96  |      0.919 |\n",
      "| 1.0          |       0.858 |    0.653 |      0.742 |\n",
      "| weighted avg |       0.876 |    0.877 |      0.871 |\n",
      "\n",
      "### floods\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.963 |    0.993 |      0.978 |\n",
      "| 1.0          |       0.869 |    0.561 |      0.681 |\n",
      "| weighted avg |       0.956 |    0.958 |      0.954 |\n",
      "\n",
      "### storm\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.962 |    0.976 |      0.969 |\n",
      "| 1.0          |       0.728 |    0.625 |      0.673 |\n",
      "| weighted avg |       0.941 |    0.944 |      0.942 |\n",
      "\n",
      "### fire\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.992 |    0.998 |      0.995 |\n",
      "| 1.0          |       0.593 |    0.242 |      0.344 |\n",
      "| weighted avg |       0.988 |    0.991 |      0.989 |\n",
      "\n",
      "### earthquake\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.98  |    0.99  |      0.985 |\n",
      "| 1.0          |       0.886 |    0.792 |      0.836 |\n",
      "| weighted avg |       0.971 |    0.972 |      0.971 |\n",
      "\n",
      "### cold\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.987 |    0.996 |      0.991 |\n",
      "| 1.0          |       0.675 |    0.397 |      0.5   |\n",
      "| weighted avg |       0.98  |    0.983 |      0.981 |\n",
      "\n",
      "### other_weather\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.954 |    0.994 |      0.974 |\n",
      "| 1.0          |       0.52  |    0.116 |      0.19  |\n",
      "| weighted avg |       0.932 |    0.949 |      0.934 |\n",
      "\n",
      "### direct_report\n",
      "|              |   precision |   recall |   f1-score |\n",
      "|:-------------|------------:|---------:|-----------:|\n",
      "| 0.0          |       0.869 |    0.966 |      0.915 |\n",
      "| 1.0          |       0.734 |    0.395 |      0.513 |\n",
      "| weighted avg |       0.843 |    0.855 |      0.837 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/chrismo/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "y_test_df = pd.DataFrame(y_test, columns=y_test.columns)\n",
    "predictions_df = pd.DataFrame(y_pred, columns=y_test_df.columns)\n",
    "\n",
    "print(\"## Detailed Metrics Breakdown by Category\")\n",
    "\n",
    "overall_metrics = []\n",
    "\n",
    "for column in y_test_df.columns:\n",
    "    print(f\"\\n### {column}\")\n",
    "    report = classification_report(y_test_df[column], predictions_df[column], output_dict=True)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    class_labels = sorted(df_report.index.drop(['accuracy', 'macro avg', 'weighted avg']))\n",
    "    df_report = df_report.loc[class_labels + ['weighted avg'], ['precision', 'recall', 'f1-score']].round(3)\n",
    "    \n",
    "    print(tabulate(df_report, headers='keys', tablefmt='pipe', showindex=True))\n",
    "    \n",
    "    weighted_avg = df_report.loc['weighted avg']\n",
    "    overall_metrics.append({\n",
    "        'Category': column,\n",
    "        'Precision': weighted_avg['precision'],\n",
    "        'Recall': weighted_avg['recall'],\n",
    "        'F1-score': weighted_avg['f1-score']\n",
    "    })\n",
    "\n",
    "# Store overall_metrics for use in Part 2\n",
    "overall_df = pd.DataFrame(overall_metrics).set_index('Category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Overall Performance Summary\n",
      "| Category               |   Precision |   Recall |   F1-score |\n",
      "|:-----------------------|------------:|---------:|-----------:|\n",
      "| request                |       0.896 |    0.902 |      0.893 |\n",
      "| offer                  |       0.99  |    0.995 |      0.992 |\n",
      "| aid_related            |       0.766 |    0.766 |      0.761 |\n",
      "| medical_help           |       0.913 |    0.928 |      0.913 |\n",
      "| medical_products       |       0.95  |    0.957 |      0.949 |\n",
      "| search_and_rescue      |       0.974 |    0.978 |      0.972 |\n",
      "| security               |       0.969 |    0.982 |      0.974 |\n",
      "| military               |       0.965 |    0.972 |      0.966 |\n",
      "| water                  |       0.964 |    0.966 |      0.965 |\n",
      "| food                   |       0.955 |    0.956 |      0.955 |\n",
      "| shelter                |       0.947 |    0.951 |      0.948 |\n",
      "| clothing               |       0.988 |    0.989 |      0.988 |\n",
      "| money                  |       0.978 |    0.982 |      0.979 |\n",
      "| missing_people         |       0.989 |    0.99  |      0.987 |\n",
      "| refugees               |       0.962 |    0.969 |      0.964 |\n",
      "| death                  |       0.969 |    0.972 |      0.969 |\n",
      "| other_aid              |       0.849 |    0.875 |      0.838 |\n",
      "| infrastructure_related |       0.908 |    0.936 |      0.912 |\n",
      "| transport              |       0.952 |    0.96  |      0.95  |\n",
      "| buildings              |       0.96  |    0.964 |      0.958 |\n",
      "| electricity            |       0.975 |    0.98  |      0.975 |\n",
      "| tools                  |       0.987 |    0.993 |      0.99  |\n",
      "| hospitals              |       0.986 |    0.991 |      0.988 |\n",
      "| shops                  |       0.993 |    0.996 |      0.995 |\n",
      "| aid_centers            |       0.977 |    0.987 |      0.981 |\n",
      "| other_infrastructure   |       0.935 |    0.956 |      0.938 |\n",
      "| weather_related        |       0.876 |    0.877 |      0.871 |\n",
      "| floods                 |       0.956 |    0.958 |      0.954 |\n",
      "| storm                  |       0.941 |    0.944 |      0.942 |\n",
      "| fire                   |       0.988 |    0.991 |      0.989 |\n",
      "| earthquake             |       0.971 |    0.972 |      0.971 |\n",
      "| cold                   |       0.98  |    0.983 |      0.981 |\n",
      "| other_weather          |       0.932 |    0.949 |      0.934 |\n",
      "| direct_report          |       0.843 |    0.855 |      0.837 |\n",
      "\n",
      "## Best and Worst Performing Categories\n",
      "**Best:** shops (F1-score: 0.995)\n",
      "**Worst:** aid_related (F1-score: 0.761)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n## Overall Performance Summary\")\n",
    "print(tabulate(overall_df, headers='keys', tablefmt='pipe', showindex=True))\n",
    "\n",
    "print(\"\\n## Best and Worst Performing Categories\")\n",
    "best_category = overall_df['F1-score'].idxmax()\n",
    "worst_category = overall_df['F1-score'].idxmin()\n",
    "print(f\"**Best:** {best_category} (F1-score: {overall_df.loc[best_category, 'F1-score']:.3f})\")\n",
    "print(f\"**Worst:** {worst_category} (F1-score: {overall_df.loc[worst_category, 'F1-score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gg = {\n",
    "                'classifier__estimator__max_depth': [3, 6, 9],\n",
    "                'classifier__estimator__learning_rate': [0.01, 0.1, 0.3],\n",
    "                'classifier__estimator__n_estimators': [100, 200, 300],\n",
    "                'classifier__estimator__subsample': [0.6, 0.8, 1.0],\n",
    "                'classifier__estimator__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "                            estimator=pipeline,\n",
    "                            param_grid=param_gg,\n",
    "                            cv=3,\n",
    "                            n_jobs=1,\n",
    "                            verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "#preditcitng using best estimator \n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_grid = cv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load ??? omo\n",
    "\n",
    "hehehe\n",
    "\n",
    "ok sha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train_classifier.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
